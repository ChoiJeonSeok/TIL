# 하둡(Hadoop) 파일시스템 (HDFS) 사용자 명령어

### 파일 및 디렉토리 조회 및 정보 확인
- `hdfs dfs -ls [PATH]`: 지정된 경로의 파일 및 디렉토리 목록을 표시한다.
- `hdfs dfs -du PATH [PATH ...]`: 파일 크기를 나타낸다.
- `hdfs dfs -dus PATH [PATH ...]`: du와 비슷하게 파일 크기를 나타낸다.
- `hdfs dfs -stat FORMAT PATH`: 지정된 파일이나 디렉토리에 대한 통계 정보를 보여준다.
- `hdfs dfs -tail FILE`: 지정된 파일의 마지막 부분을 출력한다.

### 파일 및 디렉토리 관리
- `hdfs dfs -mkdir [PATH]`: 새 디렉토리를 생성한다.
- `hdfs dfs -rm [-r] PATH`: 파일 또는 디렉토리를 삭제한다.
- `hdfs dfs -mv SRC DST`: 파일 또는 디렉토리를 새 위치로 이동한다.
- `hdfs dfs -touchz FILE`: 새로운 파일을 생성하거나, 이미 존재하는 파일의 타임스탬프를 현재 시간으로 갱신한다.

### 파일 및 디렉토리 권한 및 소유권 관리
- `hdfs dfs -chgrp [-R] GROUP PATH [PATH ...]`: 파일과 디렉토리에 대한 그룹을 변경한다.
- `hdfs dfs -chmod [-R] MODE [, MODE ...] PATH [PATH ...]`: 파일과 디렉토리의 권한을 변경한다.
- `hdfs dfs -chown [-R] [OWNER] [: [GROUP]] PATH [PATH ...]`: 파일과 디렉토리의 소유자를 변경한다.

### 파일 복사 및 이동
- `hdfs dfs -copyFromLocal LOCALSRC [ LOCALSRC ...] DST`: 로컬 파일 시스템으로부터 파일들을 복사한다.
- `hdfs dfs -copyToLocal [-ignorecrc] [-crc] SRC [SRC ...] LOCALDST`: 파일들을 로컬 파일 시스템으로 복사한다.
- `hdfs dfs -cp SRC [SRC ...] DST`: 소스에 있는 파일들을 목적지로 복사한다.
- `hdfs dfs -getmerge SRC DST`: 여러 파일을 하나의 파일로 병합하여 로컬 파일 시스템으로 복사한다.

### 검색 및 카운트
- `hdfs dfs -find PATH -name PATTERN`: 주어진 패턴과 일치하는 파일 또는 디렉토리를 검색한다.
- `hdfs dfs -count [-q] PATH [PATH ...]`: PATH에 있는 모든 파일과 디렉토리에 대한 이름, 사용된 바이트 수, 파일 개수, 하위 디렉토리 개수를 출력한다.
- `hdfs dfs -df [-h] [PATH]`: HDFS의 사용 가능한 공간과 사용 중인 공간을 보여준다.

### 파일 내용 보기
- `hdfs dfs -cat FILE [FILE ...]`: 파일의 내용을 나타낸다.


# 하둡(Hadoop) 파일시스템 (HDFS) 관리자 명령어
- Hadoop HDFS 관리자 명령어는 클러스터의 상태를 관리하고, 시스템 설정을 조정하며, 시스템 관리와 관련된 고급 작업을 수행하는 데 사용된다.

### 클러스터 관리 및 모니터링
- `hdfs dfsadmin -report`: 클러스터의 기본 통계 및 상태를 보고한다.
- `hdfs dfsadmin -safemode enter|leave`: 클러스터의 안전 모드를 수동으로 활성화하거나 비활성화한다.
- `hdfs dfsadmin -refreshNodes`: Namenode에 데이터 노드의 집합을 업데이트한다.

### 파일 시스템 체크 및 복구
- `hdfs fsck [path] [option]`: 파일 시스템의 건강 상태를 진단하고, 누락된 파일이나 블록을 찾는다.

### 시스템 설정 및 구성
- `hdfs getconf [option]`: Hadoop 클러스터의 구성 정보를 가져온다.

### 스냅샷 및 백업 관리
- `hdfs snapshot [option]`: HDFS 내의 스냅샷을 관리한다.

### 주의
- 관리자 명령어를 사용하기 위해서는 관리자 권한이 필요하며, 클러스터 전체 성능과 안정성에 큰 영향을 줄 수 있다.


## Hadoop 문제 발생 및 해결 과정

- Hadoop HDFS 클러스터에서 특정 데이터 노드가 예상치 못한 방식으로 작동하고 있다. 네트워크 연결이 불안정하거나, 디스크 오류 또는 성능 저하의 원인일 수 있다.
- 해당 노드에 저장된 데이터의 무결성에 문제가 있을 가능성이 있는 경우. 데이터가 잘못 저장되거나 손상되었을 수 있다.

### 문제 해결 과정

1. **초기 상태 확인**
   - **상황**: 클러스터의 전반적인 상태를 파악해야 한다.
   - **해결**: `hdfs dfsadmin -report` 명령어를 사용하여 클러스터의 상태를 확인한다. 이 명령어는 각 데이터 노드의 상태, 저장된 데이터의 양, 클러스터의 총 용량 등을 보여준다.

2. **특정 데이터 노드 점검**
   - **상황**: 문제가 있는 것으로 의심되는 데이터 노드의 상세한 정보가 필요하다.
   - **해결**: `hdfs dfsadmin -report`의 출력 결과를 통해 해당 데이터 노드의 상태, 저장 공간, 블록 정보 등을 검토한다.

3. **파일 시스템의 무결성 체크**
   - **상황**: 전체 HDFS의 데이터 무결성을 확인해야 한다.
   - **해결**: `hdfs fsck /` 명령어를 사용하여 HDFS의 전체 파일 시스템을 체크한다. 이를 통해 누락된 블록이나 복제되지 않은 블록 등의 문제를 확인할 수 있다.

4. **문제 있는 데이터 노드의 재시작 또는 제거**
   - **상황**: 문제가 있는 데이터 노드를 재시작하거나 클러스터에서 제거해야 할 수도 있다.
   - **해결**: 해당 데이터 노드를 재시작하거나 `hdfs dfsadmin -refreshNodes` 명령어를 사용하여 안전하게 클러스터에서 해당 노드를 제거한다.

5. **복제 인수 조정**
   - **상황**: 데이터의 안전한 복제를 위해 필요한 경우 복제 인수를 조정해야 한다.
   - **해결**: `hdfs dfs -setrep -w [복제 인수] [경로]` 명령어를 사용하여 특정 파일이나 디렉토리의 복제 인수를 조정한다.

6. **안전 모드 활성화**
   - **상황**: 클러스터를 안전하게 유지하면서 유지 보수 작업을 수행할 필요가 있다.
   - **해결**: `hdfs dfsadmin -safemode enter` 명령어를 사용하여 클러스터를 안전 모드로 전환한다. 안전 모드에서는 변경 작업이 제한된다.

7. **데이터 복구 및 백업**
   - **상황**: 손상된 데이터를 복구하거나 중요 데이터를 백업해야 한다.
   - **해결**: `hdfs dfs -copyToLocal [HDFS 경로] [로컬 경로]` 명령어를 사용하여 중요 데이터를 로컬 시스템으로 백업한다.

8. **안전 모드 해제 및 시스템 재시작**
   - **상황**: 유지 보수 작업이 완료되고 정상적인 운영으로 돌아가야 한다.
   - **해결**: `hdfs dfsadmin -safemode leave` 명령어를 사용하여 안전 모드를 해제하고 필요에 따라 Hadoop 클러스터를 재시작한다.
